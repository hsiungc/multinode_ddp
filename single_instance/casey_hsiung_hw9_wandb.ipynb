{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7270c2b",
   "metadata": {},
   "source": [
    "# 251 HW9 - ImageNet Single Instance/GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bd90df",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "846f07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce1719f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import subprocess\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba3a63",
   "metadata": {},
   "source": [
    "#### Weights & Biases Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc57bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhsiungc\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/wandb/run-20230313_024510-z51q55t3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hsiungc/251-lab9/runs/z51q55t3' target=\"_blank\">daily-firefly-32</a></strong> to <a href='https://wandb.ai/hsiungc/251-lab9' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hsiungc/251-lab9' target=\"_blank\">https://wandb.ai/hsiungc/251-lab9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hsiungc/251-lab9/runs/z51q55t3' target=\"_blank\">https://wandb.ai/hsiungc/251-lab9/runs/z51q55t3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hsiungc/251-lab9/runs/z51q55t3?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f99ba52faf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "wandb.init(project=\"251-lab9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1ee94",
   "metadata": {},
   "source": [
    "#### Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b80604",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa883c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c14ea42",
   "metadata": {},
   "source": [
    "#### Hyperparameters & Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5153eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df4b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "EPOCHS = 1\n",
    "LR = 0.001\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=784\n",
    "VAL_BATCH=784\n",
    "WORKERS=2\n",
    "TRAINDIR=\"/data/ebs/train\"\n",
    "VALDIR=\"/data/ebs/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd1fae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a298401",
   "metadata": {},
   "source": [
    "#### Set CUDA Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ec9e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "672515c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b68be11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "203f617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92addc91",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5e9bee",
   "metadata": {},
   "source": [
    "#### NVIDIA SMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b702118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_utilization():\n",
    "    result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv'], stdout=subprocess.PIPE)\n",
    "    output = result.stdout.decode('utf-8')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b2f21",
   "metadata": {},
   "source": [
    "#### Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66db10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    scaler = GradScaler()\n",
    "        \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        images = images.cuda(GPU, non_blocking=True)\n",
    "        target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with autocast(dtype=torch.float16):\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        wandb.log({'accuracy1': acc1, 'accuracy5': acc5, 'loss': loss, 'learningrate': LR}, step=i)\n",
    "            \n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83ea2a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        \n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            wandb.log({'val_accuracy1': acc1, 'val_accuracy5': acc5, 'val_loss': loss, 'val_learningrate': LR}, step=1)            \n",
    "            \n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec97705",
   "metadata": {},
   "source": [
    "#### Checkpoint & Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35a8029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0468d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50efce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0040f3e",
   "metadata": {},
   "source": [
    "#### Learning Rate & Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1d37d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67819123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52068a69",
   "metadata": {},
   "source": [
    "#### Normalization & Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ac37a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3961cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    #transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "589e37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b30777",
   "metadata": {},
   "source": [
    "#### Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6f979eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7524684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=True,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b4dace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdac0053",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526faca0",
   "metadata": {},
   "source": [
    "#### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21f26113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.__dict__[ARCH](pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fc4ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda(GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742637e2",
   "metadata": {},
   "source": [
    "#### Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "015e56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3520bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0531f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e540326",
   "metadata": {},
   "source": [
    "#### Training & Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2391dd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/1635]\tTime  8.537 ( 8.537)\tData  4.359 ( 4.359)\tLoss 1.0076e+00 (1.0076e+00)\tAcc@1  72.70 ( 72.70)\tAcc@5  92.47 ( 92.47)\n",
      "Epoch: [0][  50/1635]\tTime  2.623 ( 1.866)\tData  2.187 ( 1.356)\tLoss 9.8724e-01 (9.7196e-01)\tAcc@1  75.51 ( 75.13)\tAcc@5  91.45 ( 92.43)\n",
      "Epoch: [0][ 100/1635]\tTime  3.894 ( 2.127)\tData  3.458 ( 1.653)\tLoss 9.5116e-01 (9.4817e-01)\tAcc@1  76.15 ( 75.76)\tAcc@5  92.22 ( 92.68)\n",
      "Epoch: [0][ 150/1635]\tTime  3.423 ( 2.306)\tData  2.987 ( 1.844)\tLoss 9.1579e-01 (9.3560e-01)\tAcc@1  75.38 ( 75.95)\tAcc@5  92.35 ( 92.83)\n",
      "Epoch: [0][ 200/1635]\tTime  4.172 ( 2.393)\tData  3.736 ( 1.938)\tLoss 9.5504e-01 (9.2757e-01)\tAcc@1  76.28 ( 76.13)\tAcc@5  93.11 ( 92.95)\n",
      "Epoch: [0][ 250/1635]\tTime  4.523 ( 2.430)\tData  4.087 ( 1.979)\tLoss 8.2480e-01 (9.2096e-01)\tAcc@1  79.97 ( 76.30)\tAcc@5  94.01 ( 93.04)\n",
      "Epoch: [0][ 300/1635]\tTime  4.606 ( 2.451)\tData  4.170 ( 2.002)\tLoss 8.6754e-01 (9.1565e-01)\tAcc@1  78.70 ( 76.37)\tAcc@5  92.98 ( 93.10)\n",
      "Epoch: [0][ 350/1635]\tTime  3.056 ( 2.462)\tData  2.620 ( 2.015)\tLoss 9.0896e-01 (9.1262e-01)\tAcc@1  76.15 ( 76.43)\tAcc@5  93.24 ( 93.14)\n",
      "Epoch: [0][ 400/1635]\tTime  3.615 ( 2.480)\tData  3.179 ( 2.034)\tLoss 9.0727e-01 (9.0784e-01)\tAcc@1  76.79 ( 76.52)\tAcc@5  93.24 ( 93.19)\n",
      "Epoch: [0][ 450/1635]\tTime  3.122 ( 2.500)\tData  2.686 ( 2.056)\tLoss 7.8356e-01 (9.0539e-01)\tAcc@1  80.23 ( 76.58)\tAcc@5  94.77 ( 93.23)\n",
      "Epoch: [0][ 500/1635]\tTime  4.522 ( 2.518)\tData  4.085 ( 2.074)\tLoss 9.1123e-01 (9.0301e-01)\tAcc@1  76.79 ( 76.62)\tAcc@5  93.11 ( 93.27)\n",
      "Epoch: [0][ 550/1635]\tTime  4.878 ( 2.530)\tData  4.442 ( 2.087)\tLoss 9.5471e-01 (9.0080e-01)\tAcc@1  76.28 ( 76.69)\tAcc@5  92.73 ( 93.30)\n",
      "Epoch: [0][ 600/1635]\tTime  4.637 ( 2.536)\tData  4.201 ( 2.094)\tLoss 9.0917e-01 (8.9829e-01)\tAcc@1  77.17 ( 76.73)\tAcc@5  93.37 ( 93.33)\n",
      "Epoch: [0][ 650/1635]\tTime  4.764 ( 2.541)\tData  4.325 ( 2.098)\tLoss 8.2026e-01 (8.9680e-01)\tAcc@1  79.59 ( 76.76)\tAcc@5  94.26 ( 93.35)\n",
      "Epoch: [0][ 700/1635]\tTime  4.696 ( 2.548)\tData  4.260 ( 2.106)\tLoss 8.8355e-01 (8.9468e-01)\tAcc@1  77.42 ( 76.80)\tAcc@5  93.11 ( 93.36)\n",
      "Epoch: [0][ 750/1635]\tTime  4.922 ( 2.555)\tData  4.486 ( 2.113)\tLoss 8.4079e-01 (8.9250e-01)\tAcc@1  77.42 ( 76.85)\tAcc@5  94.01 ( 93.38)\n",
      "Epoch: [0][ 800/1635]\tTime  5.133 ( 2.563)\tData  4.694 ( 2.122)\tLoss 8.7816e-01 (8.9015e-01)\tAcc@1  77.04 ( 76.91)\tAcc@5  94.01 ( 93.41)\n",
      "Epoch: [0][ 850/1635]\tTime  5.024 ( 2.569)\tData  4.588 ( 2.129)\tLoss 8.3625e-01 (8.8914e-01)\tAcc@1  77.93 ( 76.93)\tAcc@5  94.64 ( 93.43)\n",
      "Epoch: [0][ 900/1635]\tTime  4.748 ( 2.574)\tData  4.312 ( 2.133)\tLoss 8.4728e-01 (8.8731e-01)\tAcc@1  76.66 ( 76.98)\tAcc@5  93.88 ( 93.44)\n",
      "Epoch: [0][ 950/1635]\tTime  4.823 ( 2.577)\tData  4.387 ( 2.137)\tLoss 9.0898e-01 (8.8616e-01)\tAcc@1  75.77 ( 76.99)\tAcc@5  94.39 ( 93.46)\n",
      "Epoch: [0][1000/1635]\tTime  5.059 ( 2.581)\tData  4.623 ( 2.141)\tLoss 8.3574e-01 (8.8556e-01)\tAcc@1  79.34 ( 77.00)\tAcc@5  94.64 ( 93.47)\n",
      "Epoch: [0][1050/1635]\tTime  4.867 ( 2.583)\tData  4.431 ( 2.143)\tLoss 8.7965e-01 (8.8357e-01)\tAcc@1  78.70 ( 77.04)\tAcc@5  93.24 ( 93.49)\n",
      "Epoch: [0][1100/1635]\tTime  4.882 ( 2.583)\tData  4.446 ( 2.144)\tLoss 8.3767e-01 (8.8253e-01)\tAcc@1  79.46 ( 77.07)\tAcc@5  92.86 ( 93.51)\n",
      "Epoch: [0][1150/1635]\tTime  4.796 ( 2.585)\tData  4.360 ( 2.146)\tLoss 8.4636e-01 (8.8120e-01)\tAcc@1  77.17 ( 77.11)\tAcc@5  93.75 ( 93.52)\n",
      "Epoch: [0][1200/1635]\tTime  4.755 ( 2.585)\tData  4.319 ( 2.146)\tLoss 7.7945e-01 (8.8022e-01)\tAcc@1  78.95 ( 77.13)\tAcc@5  95.28 ( 93.53)\n",
      "Epoch: [0][1250/1635]\tTime  4.844 ( 2.586)\tData  4.408 ( 2.146)\tLoss 7.9375e-01 (8.7946e-01)\tAcc@1  78.57 ( 77.14)\tAcc@5  95.28 ( 93.53)\n",
      "Epoch: [0][1300/1635]\tTime  5.171 ( 2.592)\tData  4.735 ( 2.152)\tLoss 8.9402e-01 (8.7875e-01)\tAcc@1  74.49 ( 77.16)\tAcc@5  92.86 ( 93.54)\n",
      "Epoch: [0][1350/1635]\tTime  4.999 ( 2.596)\tData  4.563 ( 2.157)\tLoss 8.9517e-01 (8.7763e-01)\tAcc@1  76.02 ( 77.18)\tAcc@5  94.26 ( 93.56)\n",
      "Epoch: [0][1400/1635]\tTime  4.947 ( 2.605)\tData  4.511 ( 2.166)\tLoss 9.1147e-01 (8.7625e-01)\tAcc@1  77.93 ( 77.22)\tAcc@5  93.37 ( 93.57)\n",
      "Epoch: [0][1450/1635]\tTime  4.611 ( 2.611)\tData  4.175 ( 2.172)\tLoss 8.9265e-01 (8.7562e-01)\tAcc@1  75.89 ( 77.24)\tAcc@5  93.62 ( 93.58)\n",
      "Epoch: [0][1500/1635]\tTime  5.139 ( 2.618)\tData  4.703 ( 2.180)\tLoss 8.4928e-01 (8.7512e-01)\tAcc@1  76.15 ( 77.24)\tAcc@5  94.77 ( 93.58)\n",
      "Epoch: [0][1550/1635]\tTime  6.030 ( 2.627)\tData  5.594 ( 2.188)\tLoss 8.4398e-01 (8.7444e-01)\tAcc@1  75.89 ( 77.26)\tAcc@5  94.77 ( 93.59)\n",
      "Epoch: [0][1600/1635]\tTime  6.738 ( 2.631)\tData  6.302 ( 2.193)\tLoss 9.3252e-01 (8.7409e-01)\tAcc@1  76.40 ( 77.26)\tAcc@5  92.47 ( 93.59)\n",
      "utilization.gpu [%]\n",
      "83 %\n",
      "\n",
      "Test: [ 0/64]\tTime  7.822 ( 7.822)\tLoss 6.4946e-01 (6.4946e-01)\tAcc@1  82.40 ( 82.40)\tAcc@5  94.77 ( 94.77)\n",
      "Test: [50/64]\tTime  3.803 ( 2.802)\tLoss 1.6773e+00 (1.2023e+00)\tAcc@1  63.01 ( 70.13)\tAcc@5  82.65 ( 89.56)\n",
      "lr: [0.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy1</td><td>▃▃▄▃▁▆▂▂▃▂▁▃▅▁▄▄▂▇▅▄▇▅▃▅▆▅▄▃▃▄▄▄▅█▅▃▆▅▃▅</td></tr><tr><td>accuracy5</td><td>▃▆▂▁▁▅▅▂▅▄▄▄▃▃▇▅▄▄▄▁▅▄▃▆█▃▃▅▅▂▅▇▇█▆▄▄▆▅▃</td></tr><tr><td>learningrate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▅▅▆▅█▄▅▆▄▅▆▄▄▆▄▄▅▃▄▅▃▄▅▃▁▃▅▄▃▄▄▃▂▁▂▅▄▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy1</td><td>81.98198</td></tr><tr><td>accuracy5</td><td>92.79279</td></tr><tr><td>learningrate</td><td>0.001</td></tr><tr><td>loss</td><td>0.8003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">daily-firefly-32</strong> at: <a href='https://wandb.ai/hsiungc/251-lab9/runs/z51q55t3' target=\"_blank\">https://wandb.ai/hsiungc/251-lab9/runs/z51q55t3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230313_024510-z51q55t3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "#    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    utilization = get_gpu_utilization()\n",
    "    print(utilization)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "    \n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab790c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
